{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb98470-c136-471d-a63e-d50d8eb09c57",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: f63c1003-937c-4325-b539-527a20b7cd8a\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3123d3d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc2baff-5e8b-4733-9899-16f248777b23",
   "metadata": {
    "height": 247,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When finding projects to build your experience, there are several steps you can take. First, you can join existing projects by asking to join someone else's project if they have an idea. Additionally, you can develop a side hustle or personal project that may or may not develop into something bigger. It's important to choose projects that will help you grow technically, but are also challenging enough to stretch your skills without being too difficult. Having good teammates or people to discuss things with is also important, as you can learn a lot from the people around you. Finally, consider if the project can be a stepping stone to larger projects in terms of technical complexity and business impact.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1ac5",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ead7dc1-71b2-4001-918f-bf8d610fd3fd",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "How can teamwork contribute to success in AI?\n",
      "What is the importance of networking in AI?\n",
      "What are some good habits to develop for a successful career?\n",
      "How can altruism be beneficial in building a career?\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "What is the first step to becoming good at AI?\n",
      "What are some common challenges in AI?\n",
      "Is it normal to find parts of AI challenging?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87a278f8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d5204e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the keys to building a career in AI?', 'How can teamwork contribute to success in AI?', 'What is the importance of networking in AI?', 'What are some good habits to develop for a successful career?', 'How can altruism be beneficial in building a career?', 'What is imposter syndrome and how does it relate to AI?', 'Who are some accomplished individuals who have experienced imposter syndrome?', 'What is the first step to becoming good at AI?', 'What are some common challenges in AI?', 'Is it normal to find parts of AI challenging?', 'What is the right AI job for me?']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c063c9c7-bf1e-4b24-9a22-d4281c0f954e",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f754bed-d16f-4c8d-a1a1-b36096272570",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dbdfbcc-aac7-4805-9894-4fc016c66bf6",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e14f512b-601c-42d0-bfac-bf41d9c577e7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2da4a602-0d56-4bf8-9fa6-03ef0b7e254b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_fe8327418bf727b51a190b0a1f18e8ea</td>\n",
       "      <td>\"What are the keys to building a career in AI?\"</td>\n",
       "      <td>\"The keys to building a career in AI are learn...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_fe8327418bf727b51a1...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T09:18:05.194478\", \"...</td>\n",
       "      <td>2023-12-02T09:18:09.226558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
       "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
       "      <td>[{'args': {'source': 'PAGE 1Founder, DeepLearn...</td>\n",
       "      <td>4</td>\n",
       "      <td>2180</td>\n",
       "      <td>0.003351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_db20832a40bc759ca59ec658f298de64</td>\n",
       "      <td>\"How can teamwork contribute to success in AI?\"</td>\n",
       "      <td>\"Collaborating and working in teams is crucial...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_db20832a40bc759ca59...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T09:18:09.415025\", \"...</td>\n",
       "      <td>2023-12-02T09:18:11.642646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
       "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>2</td>\n",
       "      <td>1712</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_5da84cb5b6d142ac24357931eb382e1b</td>\n",
       "      <td>\"What is the importance of networking in AI?\"</td>\n",
       "      <td>\"Networking is important in AI because it allo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_5da84cb5b6d142ac243...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T09:18:11.830380\", \"...</td>\n",
       "      <td>2023-12-02T09:18:14.620496</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
       "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>2</td>\n",
       "      <td>1699</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_a0dc568ac7fdc39c367cf08192d83222</td>\n",
       "      <td>\"What are some good habits to develop for a su...</td>\n",
       "      <td>\"Developing good habits is crucial for a succe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a0dc568ac7fdc39c367...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T09:18:14.819664\", \"...</td>\n",
       "      <td>2023-12-02T09:18:17.459392</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
       "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>2</td>\n",
       "      <td>1676</td>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_44a60417f409af801a14d8bac6677172</td>\n",
       "      <td>\"How can altruism be beneficial in building a ...</td>\n",
       "      <td>\"Altruism can be beneficial in building a care...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_44a60417f409af801a1...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T09:18:17.654731\", \"...</td>\n",
       "      <td>2023-12-02T09:18:19.973695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
       "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
       "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
       "      <td>2</td>\n",
       "      <td>1669</td>\n",
       "      <td>0.002541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "2  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "3  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "4  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_fe8327418bf727b51a190b0a1f18e8ea   \n",
       "1  record_hash_db20832a40bc759ca59ec658f298de64   \n",
       "2  record_hash_5da84cb5b6d142ac24357931eb382e1b   \n",
       "3  record_hash_a0dc568ac7fdc39c367cf08192d83222   \n",
       "4  record_hash_44a60417f409af801a14d8bac6677172   \n",
       "\n",
       "                                               input  \\\n",
       "0    \"What are the keys to building a career in AI?\"   \n",
       "1    \"How can teamwork contribute to success in AI?\"   \n",
       "2      \"What is the importance of networking in AI?\"   \n",
       "3  \"What are some good habits to develop for a su...   \n",
       "4  \"How can altruism be beneficial in building a ...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"The keys to building a career in AI are learn...    -   \n",
       "1  \"Collaborating and working in teams is crucial...    -   \n",
       "2  \"Networking is important in AI because it allo...    -   \n",
       "3  \"Developing good habits is crucial for a succe...    -   \n",
       "4  \"Altruism can be beneficial in building a care...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_fe8327418bf727b51a1...   \n",
       "1  {\"record_id\": \"record_hash_db20832a40bc759ca59...   \n",
       "2  {\"record_id\": \"record_hash_5da84cb5b6d142ac243...   \n",
       "3  {\"record_id\": \"record_hash_a0dc568ac7fdc39c367...   \n",
       "4  {\"record_id\": \"record_hash_44a60417f409af801a1...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-02T09:18:05.194478\", \"...   \n",
       "1  {\"start_time\": \"2023-12-02T09:18:09.415025\", \"...   \n",
       "2  {\"start_time\": \"2023-12-02T09:18:11.830380\", \"...   \n",
       "3  {\"start_time\": \"2023-12-02T09:18:14.819664\", \"...   \n",
       "4  {\"start_time\": \"2023-12-02T09:18:17.654731\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2023-12-02T09:18:09.226558               1.0                0.9   \n",
       "1  2023-12-02T09:18:11.642646               1.0                0.0   \n",
       "2  2023-12-02T09:18:14.620496               0.9                0.0   \n",
       "3  2023-12-02T09:18:17.459392               0.9                0.6   \n",
       "4  2023-12-02T09:18:19.973695               1.0                0.0   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0         1.000  [{'args': {'prompt': 'What are the keys to bui...   \n",
       "1         1.000  [{'args': {'prompt': 'How can teamwork contrib...   \n",
       "2         0.250  [{'args': {'prompt': 'What is the importance o...   \n",
       "3         0.750  [{'args': {'prompt': 'What are some good habit...   \n",
       "4         0.625  [{'args': {'prompt': 'How can altruism be bene...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What are the keys to bui...   \n",
       "1  [{'args': {'prompt': 'How can teamwork contrib...   \n",
       "2  [{'args': {'prompt': 'What is the importance o...   \n",
       "3  [{'args': {'prompt': 'What are some good habit...   \n",
       "4  [{'args': {'prompt': 'How can altruism be bene...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'PAGE 1Founder, DeepLearn...        4          2180   \n",
       "1  [{'args': {'source': 'Hopefully the previous c...        2          1712   \n",
       "2  [{'args': {'source': 'Hopefully the previous c...        2          1699   \n",
       "3  [{'args': {'source': 'Hopefully the previous c...        2          1676   \n",
       "4  [{'args': {'source': 'Hopefully the previous c...        2          1669   \n",
       "\n",
       "   total_cost  \n",
       "0    0.003351  \n",
       "1    0.002612  \n",
       "2    0.002586  \n",
       "3    0.002554  \n",
       "4    0.002541  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64310897-179b-4081-aab8-f08a3392a078",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path: https://s172-31-15-12p19319.lab-aws-production.deeplearning.ai/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eedcef",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea2b",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dae4a668-3699-4750-82f7-e53ae1bca3a7",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78f7678f-358d-448d-b153-11ac8e96a7fc",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f904c3-9845-4df5-9d2e-e5115160f987",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f59e2314-7cac-42f4-a552-9a8e4db641eb",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started on a personal project in AI, it is important to first identify and scope the project. Consider your career goals and choose a project that complements them. Ensure that the project is responsible, ethical, and beneficial to people. As you progress in your career, aim for projects that grow in scope, complexity, and impact over time. Building a portfolio of projects that shows skill progression can also be helpful. Additionally, consider using a simple framework for starting your AI job search and utilize informational interviews to find the right job in the AI field.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"how do I get started on a personal project in AI?\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5c10917-8846-4e73-838d-6232c906a7db",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11710e67-aba8-479e-8585-c4c611e2c1d2",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function BaseQueryEngine.query at 0x7f72b3f3aef0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x7f7134104e20 is calling an instrumented method <function BaseRetriever.retrieve at 0x7f72b3f3a290>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x7f72aef350c0) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function CompactAndRefine.get_response at 0x7f72b397dea0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x7f70660b7a80 is calling an instrumented method <function LLMPredictor.predict at 0x7f72bf7040d0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer.service_context.llm_predictor based on other object (0x7f72aeebf680) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "The keys to building a career in AI are learning foundational technical skills, working on projects, and finding a job, all of which is supported by being part of a community.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can teamwork contribute to success in AI?\n",
      "Teamwork can contribute to success in AI by allowing individuals to leverage the expertise and insights of their colleagues. When working on larger AI projects that require collaboration, the ability to lead and work effectively as a team becomes crucial. By working together, team members can share their deep technical insights, make informed decisions about technical architecture or data collection, and ultimately improve the project. Additionally, being surrounded by colleagues who are dedicated, hardworking, and continuously learning can inspire individuals to do the same, leading to greater success in AI endeavors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the importance of networking in AI?\n",
      "Networking is important in AI because it allows individuals to connect with others who have experience and knowledge in the field. By reaching out to people in their network, such as friends or alumni, individuals can receive guidance and support as they navigate their career in AI. Networking also provides opportunities for informational interviews, where individuals can learn more about specific positions and companies in the field. This can help individuals gain insights and make informed decisions when it comes to their job search in AI.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some good habits to develop for a successful career?\n",
      "Developing good habits in eating, exercise, sleep, personal relationships, work, learning, and self-care can be beneficial for a successful career. These habits can help individuals move forward while staying healthy and contribute to their overall success in their professional lives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can altruism be beneficial in building a career?\n",
      "Altruism can be beneficial in building a career by helping others while also advancing one's own career. By aiming to lift others during every step of their own journey, individuals can achieve better outcomes for themselves. This can be done by offering support, guidance, and assistance to others in their professional endeavors. By helping others succeed, individuals can build strong relationships, expand their network, and gain a positive reputation in their field. Additionally, acts of altruism can provide a sense of fulfillment and purpose, which can contribute to overall career satisfaction and personal growth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is imposter syndrome and how does it relate to AI?\n",
      "Imposter syndrome is a psychological phenomenon where individuals doubt their own abilities and fear being exposed as a fraud, despite evidence of their success. In the context of AI, newcomers to the field sometimes experience imposter syndrome, questioning whether they truly belong in the AI community and if they are competent enough. It is important to address imposter syndrome in order to encourage individuals to continue growing in AI and not let self-doubt hinder their progress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "Sheryl Sandberg, Michelle Obama, Tom Hanks, and Mike Cannon-Brookes are some accomplished individuals who have experienced imposter syndrome.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the first step to becoming good at AI?\n",
      "The first step to becoming good at AI is to learn foundational technical skills.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some common challenges in AI?\n",
      "Some common challenges in AI include keeping up-to-date with evolving technology, finding suitable projects and estimating timelines and return on investment, managing the highly iterative nature of AI projects, collaborating with stakeholders who lack expertise in AI, and struggling with technical challenges while reading research papers or tuning neural network hyperparameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f7134105db0 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it normal to find parts of AI challenging?\n",
      "Yes, it is normal to find parts of AI challenging. The author mentions that they still find many research papers challenging to read and have made mistakes while working with neural networks. They also assure the reader that everyone who has published a seminal AI paper has struggled with similar technical challenges at some point. Therefore, it is clear that finding parts of AI challenging is a common experience.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71341060e0 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the right AI job for me?\n",
      "The right AI job for you can be found by following the steps outlined in Chapter 9: Finding the Right AI Job for You. This chapter provides guidance on how to identify and pursue AI job opportunities that align with your skills, interests, and career goals. Additionally, Chapter 8: Using Informational Interviews to Find the Right Job offers valuable insights on how to gather information and make informed decisions about potential AI job opportunities. By leveraging the information and frameworks provided in these chapters, you can find the AI job that is the best fit for you.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "869d1e55-729b-45f2-a0f9-773c49d4616f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Answer Relevance  Groundedness  \\\n",
       "app_id                                                         \n",
       "Sentence Window Query Engine              0.98         0.875   \n",
       "\n",
       "                              Context Relevance   latency  total_cost  \n",
       "app_id                                                                 \n",
       "Sentence Window Query Engine           0.277778  6.272727    0.000852  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b92d0f2-2e80-48d5-92af-b3655eb03ea2",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path: https://s172-31-15-12p19319.lab-aws-production.deeplearning.ai/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2c55",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "558c639b-31eb-4c34-b6c4-fe6ae5717733",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b32265f2-0247-42df-9abe-97d52f69edcf",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "918ed568-220e-4c7c-aa60-cfa58ef1fcbd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: d4292400-5f58-40f4-93d1-189b70ae8ed9.\n",
      "> Parent node text: PAGE 21Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: f30ae8f8-1855-4dd8-b067-ce0d3438213c.\n",
      "> Parent node text: PAGE 21Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "To build a portfolio of AI projects, it is important to start with simple undertakings and gradually progress to more complex ones. This progression will demonstrate your growth and development over time. Additionally, effective communication is crucial. You should be able to explain your thinking and articulate the value of your work to others. This will help others see the potential in your projects and trust you with the necessary resources for larger endeavors.\n"
     ]
    }
   ],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db4f18a9-7b8a-4ae2-ab11-3a6a941a5afc",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerging_query_engine,\n",
    "                                                         app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99cc2cfe-7096-4fa0-aa72-094bebac35a3",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f71342d7a90 is calling an instrumented method <function BaseQueryEngine.query at 0x7f72b3f3aef0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f71342d7a90 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n",
      "A new object of type <class 'llama_index.retrievers.auto_merging_retriever.AutoMergingRetriever'> at 0x7f7134231600 is calling an instrumented method <function BaseRetriever.retrieve at 0x7f72b3f3a290>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x7f72aef350c0) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x7f7134230280 is calling an instrumented method <function BaseRetriever.retrieve at 0x7f72b3f3a290>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x7f72aef350c0) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: 0256203c-507f-497d-9780-2ea81c4740af.\n",
      "> Parent node text: PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Ca...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 939587f0-b677-4b74-ba6c-8c7425d05b94.\n",
      "> Parent node text: PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Ca...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71342d6b30 is calling an instrumented method <function CompactAndRefine.get_response at 0x7f72b397dea0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71342d6b30 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x7f6feb227ec0 is calling an instrumented method <function LLMPredictor.predict at 0x7f72bf7040d0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer.service_context.llm_predictor based on other object (0x7f72aeebf680) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f71342d7a90 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "The keys to building a career in AI include learning foundational technical skills, working on projects, finding a job, and being part of a community. Additionally, collaborating with others and being able to influence and be influenced by others is critical for success in AI.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71342d6b30 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7f71342d7a90 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7f72af422b90>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f7134233a90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can teamwork contribute to success in AI?\n",
      "Teamwork can contribute to success in AI by allowing individuals to collaborate with others, influence their teammates, and be influenced by them. This is important because when tackling large projects, working in teams is more effective than working individually. Additionally, teamwork helps in developing interpersonal and communication skills, which are crucial in the field of AI.\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 19c0865e-bfd7-47a2-bcac-cd5ea2d5a6a0.\n",
      "> Parent node text: PAGE 35Keys to Building a Career in AI CHAPTER 10\n",
      "The path to career success in AI is more comple...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 0fed46d5-00e0-4f15-bef1-fd19324872f9.\n",
      "> Parent node text: PAGE 35Keys to Building a Career in AI CHAPTER 10\n",
      "The path to career success in AI is more comple...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7f71342d6b30 is calling an instrumented method <function Refine.get_response at 0x7f72b2790ee0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app._response_synthesizer based on other object (0x7f72aef357e0) using this function.\n",
      "Error calling wrapped function predict.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 219, in predict\n",
      "    chat_response = self._llm.chat(messages)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/base.py\", line 187, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 200, in chat\n",
      "    return chat_fn(messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 254, in _chat\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 758, in wrapper\n",
      "    response: Any = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 299, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 1063, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 842, in request\n",
      "    return self._request(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 866, in _request\n",
      "    response = self._client.send(request, auth=self.custom_auth, stream=stream)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 133, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 111, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 176, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 212, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "KeyboardInterrupt\n",
      "\n",
      "Error calling wrapped function get_response.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 127, in get_response\n",
      "    response = self._give_response_single(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 182, in _give_response_single\n",
      "    program(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 53, in __call__\n",
      "    answer = self._llm_predictor.predict(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 219, in predict\n",
      "    chat_response = self._llm.chat(messages)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/base.py\", line 187, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 200, in chat\n",
      "    return chat_fn(messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 254, in _chat\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 758, in wrapper\n",
      "    response: Any = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 299, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 1063, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 842, in request\n",
      "    return self._request(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 866, in _request\n",
      "    response = self._client.send(request, auth=self.custom_auth, stream=stream)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 133, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 111, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 176, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 212, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "KeyboardInterrupt\n",
      "\n",
      "Error calling wrapped function get_response.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/compact_and_refine.py\", line 38, in get_response\n",
      "    return super().get_response(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 127, in get_response\n",
      "    response = self._give_response_single(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 182, in _give_response_single\n",
      "    program(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 53, in __call__\n",
      "    answer = self._llm_predictor.predict(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 219, in predict\n",
      "    chat_response = self._llm.chat(messages)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/base.py\", line 187, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 200, in chat\n",
      "    return chat_fn(messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 254, in _chat\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 758, in wrapper\n",
      "    response: Any = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 299, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 1063, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 842, in request\n",
      "    return self._request(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 866, in _request\n",
      "    response = self._client.send(request, auth=self.custom_auth, stream=stream)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 133, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 111, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 176, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 212, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "KeyboardInterrupt\n",
      "\n",
      "Error calling wrapped function query.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/core/base_query_engine.py\", line 30, in query\n",
      "    return self._query(str_or_query_bundle)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 171, in _query\n",
      "    response = self._response_synthesizer.synthesize(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/base.py\", line 146, in synthesize\n",
      "    response_str = self.get_response(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/compact_and_refine.py\", line 38, in get_response\n",
      "    return super().get_response(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 127, in get_response\n",
      "    response = self._give_response_single(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 182, in _give_response_single\n",
      "    program(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 53, in __call__\n",
      "    answer = self._llm_predictor.predict(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 799, in wrapper\n",
      "    raise error\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 738, in wrapper\n",
      "    rets, cost = Endpoint.track_all_costs_tally(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 377, in track_all_costs_tally\n",
      "    result, cbs = Endpoint.track_all_costs(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 303, in track_all_costs\n",
      "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 480, in _track_costs\n",
      "    result: T = thunk()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py\", line 739, in <lambda>\n",
      "    lambda: func(*bindings.args, **bindings.kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 219, in predict\n",
      "    chat_response = self._llm.chat(messages)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/base.py\", line 187, in wrapped_llm_chat\n",
      "    f_return_val = f(_self, messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 200, in chat\n",
      "    return chat_fn(messages, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 254, in _chat\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 758, in wrapper\n",
      "    response: Any = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 299, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 1063, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 842, in request\n",
      "    return self._request(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/openai/_base_client.py\", line 866, in _request\n",
      "    response = self._client.send(request, auth=self.custom_auth, stream=stream)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 133, in handle_request\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 111, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 176, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py\", line 212, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    return self._sock.recv(max_bytes)\n",
      "KeyboardInterrupt\n",
      "\n",
      "Unsure what the main output string is for the call to query.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m eval_questions:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tru_recorder_automerging \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[1;32m      3\u001b[0m         response \u001b[38;5;241m=\u001b[39m automerging_query_engine\u001b[38;5;241m.\u001b[39mquery(question)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(question)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/app.py:705\u001b[0m, in \u001b[0;36mApp.__exit__\u001b[0;34m(self, exc_type, exc_value, exc_tb)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording_contexts\u001b[38;5;241m.\u001b[39mreset(ctx\u001b[38;5;241m.\u001b[39mtoken)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m eval_questions:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tru_recorder_automerging \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[0;32m----> 3\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mautomerging_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(question)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:787\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# If stack has only 1 thing on it, we are looking at a \"root\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# call\". Create a record of the result and notify the app:\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# If this is a root call, notify app to add the completed record\u001b[39;00m\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;66;03m# into its containers:\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m         \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_add_record\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43msig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mperf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPerf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/app.py:753\u001b[0m, in \u001b[0;36mApp._on_add_record\u001b[0;34m(self, ctx, func, sig, bindings, ret, error, perf, cost)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# May block on DB.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_error(record\u001b[38;5;241m=\u001b[39mrecord, error\u001b[38;5;241m=\u001b[39merror)\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# Will block on DB, but not on feedback evaluation, depending on\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# FeedbackMode:\u001b[39;00m\n\u001b[1;32m    757\u001b[0m record\u001b[38;5;241m.\u001b[39mfeedback_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_record(record\u001b[38;5;241m=\u001b[39mrecord)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:738\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:377\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    366\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:303\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ApiKeyError:\n\u001b[1;32m    298\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome API key(s) used by LiteLLM are not set. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill not track usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:480\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    477\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:739\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 739\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/core/base_query_engine.py:30\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     29\u001b[0m     str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py:171\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    168\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    170\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 171\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/base.py:146\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    144\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    145\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 146\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    155\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:799\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39m_on_add_record(\n\u001b[1;32m    788\u001b[0m             ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    789\u001b[0m             func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             cost\u001b[38;5;241m=\u001b[39mcost\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rets\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:738\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:377\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    366\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:303\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ApiKeyError:\n\u001b[1;32m    298\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome API key(s) used by LiteLLM are not set. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill not track usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:480\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    477\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:739\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 739\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/compact_and_refine.py:38\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:799\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39m_on_add_record(\n\u001b[1;32m    788\u001b[0m             ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    789\u001b[0m             func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             cost\u001b[38;5;241m=\u001b[39mcost\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rets\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:738\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:377\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    366\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:303\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ApiKeyError:\n\u001b[1;32m    298\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome API key(s) used by LiteLLM are not set. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill not track usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:480\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    477\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:739\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 739\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py:127\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[1;32m    133\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[1;32m    134\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py:182\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    181\u001b[0m             StructuredRefineResponse,\n\u001b[0;32m--> 182\u001b[0m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py:53\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StructuredRefineResponse:\n\u001b[0;32m---> 53\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:799\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39m_on_add_record(\n\u001b[1;32m    788\u001b[0m             ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    789\u001b[0m             func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             cost\u001b[38;5;241m=\u001b[39mcost\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rets\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:738\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:377\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    366\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:303\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ApiKeyError:\n\u001b[1;32m    298\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome API key(s) used by LiteLLM are not set. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill not track usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:480\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    477\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/instruments.py:739\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    738\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 739\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    743\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py:219\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[0;34m(self, prompt, output_cls, **prompt_args)\u001b[0m\n\u001b[1;32m    217\u001b[0m     messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat_messages(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m    218\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_messages(messages)\n\u001b[0;32m--> 219\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/llms/base.py:187\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n\u001b[1;32m    179\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    180\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    181\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         },\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponseGen:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py:200\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/llama_index/llms/openai.py:254\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: Sequence[ChatMessage], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponse:\n\u001b[1;32m    253\u001b[0m     message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[0;32m--> 254\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     openai_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    260\u001b[0m     message \u001b[38;5;241m=\u001b[39m from_openai_message(openai_message)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/trulens_eval/feedback/provider/endpoint/base.py:758\u001b[0m, in \u001b[0;36mEndpoint.wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling wrapped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Get the result of the wrapped function:\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m response: Any \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m bindings \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# Get all of the callback classes suitable for handling this call.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# Note that we stored this in the INSTRUMENT attribute of the\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# wrapper method.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/resources/chat/completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/_base_client.py:866\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(request)\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_auth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase\n\u001b[1;32m    869\u001b[0m     )\n\u001b[1;32m    870\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    893\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    926\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1006\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    233\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    234\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    235\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    236\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404dec1-60ca-42fa-ac13-793a5423aa64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f545d41-0d98-446f-8214-8b59bef08d6c",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
